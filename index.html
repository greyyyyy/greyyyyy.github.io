<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/22/%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/22/%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA/" class="post-title-link" itemprop="url">卷积网络搭建</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-02-22 14:03:08 / Modified: 17:16:56" itemprop="dateCreated datePublished" datetime="2021-02-22T14:03:08+08:00">2021-02-22</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="卷积计算过程"><a href="#卷积计算过程" class="headerlink" title="卷积计算过程"></a>卷积计算过程</h1><p>全连接网络(也写作：全连接NN)中每一个神经元小球与前后相邻层的每一个神经元都有连接关系，输入是特征，输出是预测的结果<br>当网络参数过多，隐藏层数增加，很容易使模型过拟合。<br>为了减少待训练参数，则先对原始图片进行特征提取，再把提取到的特征送到全连接网络，让全连接网络输出识别结果   </p>
<p><strong>卷积计算是一种有效的特征提取方法</strong><br>一般用一个正方形的卷积核，按指定步长，在输入特征图上滑动，遍历输入特征图中的每个像素点。每一个步长，卷积核会与输入特征图出现重合区域，重合区域对应元素相乘、求和再加上偏置项，得到输出特征的一个像素点。<br><img src="https://i.loli.net/2021/02/22/TBMPohCsjU3ZNAF.png" alt="image.png">    </p>
<p><strong>🎱补充</strong>   </p>
<ul>
<li>图像的深度<br>图像是由一个个像素点构成，而计算机是用二进制来进行储存，每一个像素点所占用的bit位数，就是图像的深度。   <ul>
<li>二值图像<br>像素点取值为0或1，也就是黑白两色.像素点所占位数为1位，则深度为1  </li>
<li>灰度图像<br>像素点取值为0-255，2^8=256，所以深度是8   </li>
</ul>
</li>
<li>图像的通道<br>24位图，也就是2^24，我们用8位代表一种颜色，那么每一种颜色都是0-255的范围内，每一个像素点为(0-255,0-255,0-255),这就是三通道RGB    </li>
</ul>
<p><strong>卷积核的通道数与输入特征图的通道数一致</strong><br>如果输入特征是单通道灰图，用深度为1的单通道卷积核<br>如果输入特征是三通道彩色图，用3<em>3</em>3的卷积核或5<em>5</em>3的卷积核<br>要想让卷积核与输入特征图对应点匹配上，必须让卷积核的深度与输入特征图的深度一致<br><strong>输入特征图的深度(channel数),决定了当前层卷积核的深度:</strong><br>(上述加粗的就是原文的表述，我觉得应该不是指图像的深度，因该是图像的通道数)<br>每个卷积核在卷积计算后会得到一张输出特征图，所以当前有几个卷积核，就有几张输出特征图。<br><strong>当前层卷积核的个数，决定了当前层输出特征图的深度</strong><br>可以通过多用几个卷积核提高该层的特征提取能力<br><img src="https://i.loli.net/2021/02/22/jZkKz6gTyHlE5MQ.png" alt="image.png">  </p>
<p>每一个小颗粒都存储着待训练参数，在执行卷积计算时，这些参数是不变的。而在反向传播中，这些参数是随着梯度下降跟新的<br>卷积就是利用立体卷积核实现了参数的空间共享    </p>
<blockquote>
<p>You can imagine convolution as the mixing of information. Imagine two buckets full of information which are poured into one single bucket and then mixed according to a specific rule. Each bucket of information has its own recipe, which describes how the information in one bucket mixes with the other. So convolution is an orderly procedure where two sources of information are intertwined.</p>
</blockquote>
<h1 id="感受野Receptive-Field"><a href="#感受野Receptive-Field" class="headerlink" title="感受野Receptive Field"></a>感受野Receptive Field</h1><p><strong>定义：</strong> 卷积神经网络各输出特征图中的每个像素点，在原始输入图片上映射区域的大小<br><img src="https://i.loli.net/2021/02/22/jCZ6egWkyBzMDL5.png" alt="image.png"><br>可以看到原始的<code>5*5</code>的图用黄色的<code>3*3</code>卷积核作用，则得到了一个<code>3*3</code>的输出特征图，图上的每个像素点映射到原始输入图片是<code>3*3</code>的区域，所以其<strong>感受野是3</strong><br><img src="https://i.loli.net/2021/02/22/F6ayAlHZi2ObqTt.png" alt="image.png"><br>而如果再对这个<code>3*3</code>的输出特征图用<code>3*3</code>的卷积核作用，输出的是一个<code>1*1</code>的输出特征图，而这个输出特征图的<strong>感受野是5</strong>，因为要映射到原始图片，先映射一次，是上一个输出特征图的所有，则再映射就是原始特征图的所有了。<br><img src="https://i.loli.net/2021/02/22/n4uvsiVSPxJkFB7.png" alt="image.png"><br>而如果<code>5*5</code>的原始图直接用<code>5*5</code>的卷积核作用，得到的是<code>1*1</code>的输出特征图，<strong>感受野也是5</strong>    </p>
<p>也就是，两层的<code>3*3</code>卷积核和一层的<code>5*5</code>卷积核作用得到的输出特征图的感受野都是5；所以这两个的特征提取能力是一样的。<br>由此我们可以看到的是，特征提取能力的可以通过感受野的大小来判断。<br>那么是选择<code>两个3*3</code>还是<code>一个5*5</code>呢？<br>此时则考虑他们所承载的<strong>待训练参数量</strong>和<strong>计算量</strong>了。<br><img src="https://i.loli.net/2021/02/22/gTzqi91PBx5puWt.png" alt="image.png"><br><strong>🎱补充</strong><br>经过卷积核作用后的输出特征图的像素点个数的计算公式。<br>假设，输入特征图的宽、高为x,卷积核为m<em>m，则经过卷积核作用后的输出特征图一共有<code>(x-m+1)^2</code>个像素点<br>得到每一个像素点要进行<code>m*m</code>次乘加运算，所以总计算量为```m*m</em>(x-m+1)^2```      </p>
<p>所以在神经网络计算中常使用<code>两层3*3卷积核</code>替换<code>5*5卷积核</code>的原因   </p>
<h1 id="全零填充"><a href="#全零填充" class="headerlink" title="全零填充"></a>全零填充</h1><p>使卷积计算保持输入特征图尺寸不变，则用全零填充<br><img src="https://i.loli.net/2021/02/22/nXliHJ4Ivx73GDQ.png" alt="image.png"><br>也就是，输出特征图的维度计算公式为<code>VALID</code>部分。   </p>
<h1 id="描述卷积计算层"><a href="#描述卷积计算层" class="headerlink" title="描述卷积计算层"></a>描述卷积计算层</h1><p><img src="https://i.loli.net/2021/02/22/ALKBIh94GQErUzi.png" alt="image.png"><br><strong>🎱补充</strong><br>BN是指Batch Normalization,特就是批量标准化处理。  </p>
<h1 id="BN"><a href="#BN" class="headerlink" title="BN"></a>BN</h1><p>神经网络对0附近的数据更敏感，但会存在一些特征值偏离0的情况，所以就有了<code>标准化</code><br><strong>标准化：</strong>使数据符合以0为均值，以1为标准差的分布<br><strong>批标准化：</strong>对一小批数据(batch)，标准化处理<br>BN常用在卷积操作和激活操作之间<br><img src="https://i.loli.net/2021/02/22/kIOLWd6aJtubGRq.png" alt="image.png"><br>批标准化操作会让每个像素点进行<code>减均值并处以标准差</code>的自更新计算<br><img src="https://i.loli.net/2021/02/22/aibSC7FtvhjTJmG.png" alt="image.png"><br>通过BN操作，使得特征数据集中在激活函数线性变化区间，使得就算特征数据变化小，也能明显地提现到激活函数输出中，提升了激活函数对输入数据地区分力<br>但这样简单的标准化，使得特征数据完全满足标准正态分布，集中在激活函数中心的线性区域，是激活函数丧失；了非线性特性，因此在BN操作中为每个卷积核引入了两个可训练参数，缩放因子γ和偏移因子β<br>这两个因子会与其他带训练参数一同被训练优化，是标准正态分布后的特征数据通过缩放因子和偏移因子优化了特征数据分布的宽窄和偏移量，保证了网络的非线性表达力<br><img src="https://i.loli.net/2021/02/22/KA1q8HGwh9oFpYb.png" alt="image.png">   </p>
<h1 id="池化Pooling"><a href="#池化Pooling" class="headerlink" title="池化Pooling"></a>池化Pooling</h1><p><strong>池化用于减少特征数据量</strong><br>池化的主要方法   </p>
<ul>
<li>最大池化<br>可提取图片纹理<br>因为提取了主要特征，所以相当于纹理  </li>
<li>均值池化<br>可保留背景特征。<br><img src="https://i.loli.net/2021/02/22/hoBeALYsGSuyM2m.png" alt="image.png"><br>如图所示，用了一个2<em>2的池化核，对输入图片进行了以2为步长的池化。<br>也就是我用一个2</em>2的方框，框住了图片里对应的四个像素点，通过池化方法，比如最大池化，选择这四个像素点中最大的数作为输出的像素点值，或者均值池化，取这四个像素点的均值作为输出的像素点值，得到我们经过池化后的原图大小的四分之一。<br><img src="https://i.loli.net/2021/02/22/DZgYfNi3HB4b8Pp.png" alt="image.png"><br><img src="https://i.loli.net/2021/02/22/6udcfhL4DPYVS5H.png" alt="image.png"></li>
</ul>
<h1 id="舍弃Dropout"><a href="#舍弃Dropout" class="headerlink" title="舍弃Dropout"></a>舍弃Dropout</h1><p>为了缓解神经网络过拟合，在神经网络训练时，将隐藏层的一部分神经元按照一定概率从神经网络中暂时舍弃。在神经网络使用时，被舍弃的神经元恢复连接。   </p>
<p><img src="https://i.loli.net/2021/02/22/64PE7DiGgNWXfM5.png" alt="image.png">    </p>
<h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>卷积神经网络就是借助卷积核对输入特征进行特征提取，提取后送入全连接网络进行识别预测<br><img src="https://i.loli.net/2021/02/22/FrtYCqnyZcmDhT6.png" alt="image.png">   </p>
<p><img src="https://i.loli.net/2021/02/22/qCKZTbpyrPXxvU4.png" alt="image.png"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E5%8A%9F%E8%83%BD%E6%89%A9%E5%B1%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E5%8A%9F%E8%83%BD%E6%89%A9%E5%B1%95/" class="post-title-link" itemprop="url">神经网络八股功能扩展</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-02-21 20:02:20" itemprop="dateCreated datePublished" datetime="2021-02-21T20:02:20+08:00">2021-02-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-22 13:53:29" itemprop="dateModified" datetime="2021-02-22T13:53:29+08:00">2021-02-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="自制数据集"><a href="#自制数据集" class="headerlink" title="自制数据集"></a>自制数据集</h1><p>意思就是，若我有一堆图片，一个标签文本，如何提取做出我们的<code>x_train,y_train</code><br>首先我们将标签文本整理，第一列是图片名称，第二列就是该图片对应的标签。<br>为什么是图片名称？<br>因为，我们要提取出<code>x,y</code>也就是，我们从一个图片中提取了它的灰度值，要能够与y对应。<br>而如何提取一个图片的像素值？<br>导入<code>PIL</code>库中的<code>Image</code>,用<code>Imag.open(图片路径)</code>读入图片，<code>np.array(img.convert(&#39;L&#39;))</code>转变为灰度值的<code>np.array</code>格式，此时其实就拿到了我们的x，图片对应的灰度值，那么我们还应该做归一化处理<code>img/255</code><br>此时我们就得到了我们的x，那么要与y对应，就要保证在<code>标签的txt</code>文档中，名字与标签一一对应，再在读取图片时图片所在目录<code>path</code>加上图片名字就是图片的<code>path</code>。    </p>
<p>🎆具体代码如下<br><img src="https://i.loli.net/2021/02/21/tcNxvV1ewHmJZnp.png" alt="image.png"><br><img src="https://i.loli.net/2021/02/21/VXqHKwU9rFE41QI.png" alt="image.png"></p>
<h1 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h1><p>数据增强可以帮助扩展数据集<br>对图像的增强，就是对图像的简单形变。<br>Tensorlow2有数据增强函数<br><img src="https://i.loli.net/2021/02/21/6FDYsyQNM9ohanb.png" alt="image.png"><br><img src="https://i.loli.net/2021/02/21/EPkrO7dFKetN8y9.png" alt="image.png"><br>这个相当于前面是一种设置，然后用<code>fit()</code>把设置的参数放在我们的训练集中<code>x_train</code><br>而这里的<code>imag_gen_train_fit(x_train)</code>需要输入一个四位数据，所以要对<code>x_train.reshape(x_train.shape[0],28,28,1)</code><br>也就是将(60000,28,28) -&gt; (60000,28,28,1)<br><img src="https://i.loli.net/2021/02/21/v96z4hRuZDcOApm.png" alt="image.png">    </p>
<h1 id="断点续训"><a href="#断点续训" class="headerlink" title="断点续训"></a>断点续训</h1><p><strong>定义：</strong> 在进行神经网络训练过程中由于一些因素导致训练无法进行，需要保存当前的训练结果，下次接着训练    </p>
<h2 id="读取模型"><a href="#读取模型" class="headerlink" title="读取模型"></a>读取模型</h2><p>可直接使用tensorflow给出的函数<code>load_weights(路径文件名)</code>读取已有模型参数<br>先定义出存放模型的路径和文件名，并命名为ckpt文件<code>checkpoint_save_path = &quot;./checkpoint/mnist.ckpt&quot;</code><br><strong>🎱补充</strong> ckpt文件用于存放<code>weights、biases、gradients等</code>变量<br>在生成<code>ckpt</code>文件时会同步生成索引表，所以可以通过判断是否已有索引表，就知道是不是已经保存过模型参数了<code>if os.path.exists(checkpoint_save_path + &#39;.index&#39;):</code><br>如果有了索引表，就可以调用<code>model.load_weights(checkpoint_save_path)</code>函数，来读取模型参数。</p>
<h2 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h2><p>保存模型参数可以使用tensorflow的回调函数直接保存训练出来的参数。     </p>
<pre><code>tf.keras.callbacks.ModelCheckpoint(
    filepath = 路径文件名,   
    save_weights_only =True/False, #是否只保留模型参数
    save_best_only=True/False   #是否只保留最优结果
)
history = model.fit(callbacks=[cp_callback])</code></pre><p><img src="https://i.loli.net/2021/02/21/obsF9EQxZ3KzCNM.png" alt="image.png"></p>
<p><img src="https://i.loli.net/2021/02/21/lpXTjmz4kU29oZ5.png" alt="image.png"></p>
<h2 id="参数提取"><a href="#参数提取" class="headerlink" title="参数提取"></a>参数提取</h2><p><strong>把参数存入文本</strong><br>Tensorflow中可以用<code>model.trainable_variables</code>返回当前模型中所有可训练参数<br>可以用<code>print</code>函数打印出这些可训练参数<br>但是如果直接<code>print</code>，很多参数会被省略号替换掉,可以通过<code>np.set_printoptions(threshold=超过多少省略显示)</code>设置打印效果<br>设置为<code>np.set_printoptions(threshold=np.inf)</code>则，所有都不省略，都打印<br>这时，再<code>print(model.trainable_variables)</code>就可以打印出所有可训练参数了    </p>
<h2 id="acc-loss可视化"><a href="#acc-loss可视化" class="headerlink" title="acc/loss可视化"></a>acc/loss可视化</h2><p>在<code>model.fit()</code>中记录了<code>训练集loss、测试集loss、训练集准确率sparse_categorical_accuracy、测试集准确率val_sparse_categorical_accuracy</code>    </p>
<pre><code>history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1,
                callbacks=[cp_callback])


# 提取了model.fit函数在执行过程中，保存的训练集准确率等
acc = history.history[&apos;sparse_categorical_accuracy&apos;]
val_acc = history.history[&apos;val_sparse_categorical_accuracy&apos;]
loss = history.history[&apos;loss&apos;]
val_loss = history.history[&apos;val_loss&apos;]

plt.subplot(1, 2, 1)
plt.plot(acc, label=&apos;Training Accuracy&apos;)
plt.plot(val_acc, label=&apos;Validation Accuracy&apos;)
plt.title(&apos;Training and Validation Accuracy&apos;)
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(loss, label=&apos;Training Loss&apos;)
plt.plot(val_loss, label=&apos;Validation Loss&apos;)
plt.title(&apos;Training and Validation Loss&apos;)
plt.legend()
plt.show()</code></pre><p><img src="https://i.loli.net/2021/02/22/Z2tRlU8SGAc3p4H.png" alt="image.png"></p>
<h2 id="给图识物"><a href="#给图识物" class="headerlink" title="给图识物"></a>给图识物</h2><p>意思应该是，我现在有一个模型了，那么我要如何把我要测试的加载进去，得到相应的结果<br>运用<code>predict(输入特征,batch_size=整数)</code>返回前向传播计算结果<br>    # 复现模型<br>    model = tf.keras.models.Sequential([<br>        tf.keras.layers.Flatten(),<br>        tf.keras.layers.Dense(128,activation=’relu’),<br>        tf.keras.layers.Dense(10,activation=’softmax’)<br>    ])</p>
<pre><code># 加载参数   
model.load_weights(model_save_path)   

# 预测结果
result = model.predict(x_predict)    </code></pre><p><strong>代码思路:</strong><br>目的是，我现在训练了一个模型，有一堆测试图片，来测试这个神经网络模型<br>首先，我要加载出我的网络，也就是给出其地址，加载出参数，然后要喂入我的测试集的数据  </p>
<pre><code>model_save_path = &apos;./checkpoint/mnist.ckpt&apos;

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation=&apos;relu&apos;),
    tf.keras.layers.Dense(10, activation=&apos;softmax&apos;)])

model.load_weights(model_save_path)</code></pre><p>那么我现在时随便给的图片，大小，像素点的值也与我原本的不一样。<br>拿mnist举例，给出的全是28*28的黑底白字的图片，那么我对我的图片进行预处理。    </p>
<ul>
<li><p>法一<br>凡是，灰度后值小于200的全设为255，也就是设为白色；凡是大于的设为黑色，则反转了    </p>
</li>
<li><p>法二<br>直接反，<code>img_arr = 255-img_arr</code>    </p>
<h1 id="对图片进行处理"><a href="#对图片进行处理" class="headerlink" title="对图片进行处理"></a>对图片进行处理</h1><p>  preNum = int(input(“input the number of test pictures:”))</p>
<p>  for i in range(preNum):</p>
<pre><code>image_path = input(&quot;the path of test picture:&quot;)
img = Image.open(image_path)
img = img.resize((28, 28), Image.ANTIALIAS)
img_arr = np.array(img.convert(&apos;L&apos;))</code></pre><p>  #第二种方法，直接颠倒</p>
<pre><code>img_arr = 255 - img_arr</code></pre><p>  #第一种方法，模糊化，全部变为黑白    </p>
<pre><code>for i in range(28):
    for j in range(28):
        if img_arr[i][j] &lt; 200:
            img_arr[i][j] = 255
        else:
            img_arr[i][j] = 0</code></pre></li>
</ul>
<pre><code>#最后记得归一化处理   
img_arr = img_arr / 255.0


#img.resize((width, height),Image.ANTIALIAS)
第二个参数：
    Image.NEAREST ：低质量
    Image.BILINEAR：双线性
    Image.BICUBIC ：三次样条插值
    Image.ANTIALIAS：高质量</code></pre><p>此时我们的图片数据也准备好了，但这里要注意，我们在训练集中喂入的是三维，所以要加一维<code>x_predict = img_arr[tf.newaxis, ...]</code><br><strong>最后完整版代码：</strong><br>    from PIL import Image<br>    import numpy as np<br>    import tensorflow as tf</p>
<pre><code>model_save_path = &apos;./checkpoint/mnist.ckpt&apos;

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation=&apos;relu&apos;),
    tf.keras.layers.Dense(10, activation=&apos;softmax&apos;)])

model.load_weights(model_save_path)

preNum = int(input(&quot;input the number of test pictures:&quot;))

for i in range(preNum):
    image_path = input(&quot;the path of test picture:&quot;)
    img = Image.open(image_path)
    img = img.resize((28, 28), Image.ANTIALIAS)
    img_arr = np.array(img.convert(&apos;L&apos;))

    for i in range(28):
        for j in range(28):
            if img_arr[i][j] &lt; 200:
                img_arr[i][j] = 255
            else:
                img_arr[i][j] = 0

    img_arr = img_arr / 255.0
    x_predict = img_arr[tf.newaxis, ...]
    result = model.predict(x_predict)

    pred = tf.argmax(result, axis=1)

    print(&apos;\n&apos;)
    tf.print(pred)</code></pre><p><img src="https://i.loli.net/2021/02/22/P2Ad1vEB8ysTfxL.png" alt="image.png"><br><img src="https://i.loli.net/2021/02/22/FJqbSR7eusfYUHx.png" alt="image.png"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/19/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%9B%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/19/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%9B%9B/" class="post-title-link" itemprop="url">Tensorflow学习笔记(四)</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-02-19 14:02:50" itemprop="dateCreated datePublished" datetime="2021-02-19T14:02:50+08:00">2021-02-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-21 19:52:24" itemprop="dateModified" datetime="2021-02-21T19:52:24+08:00">2021-02-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><ul>
<li>提供六万张28*28像素点的0~9手写数字图片和标签，用于训练   </li>
<li>提供一万张28*28像素点的0~9手写数字图片和标签，用于测试 </li>
</ul>
<pre><code>#导入MNIST数据集  
mnist = tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test) =mnist.load_data()   

#将所有像素点(28*28=784)的灰度值作为输入特征，输入神经网络时，将数据拉伸为一维数组:   
tf.keras.layers.Flatten()    </code></pre><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><pre><code>import tensorflow as tf
from matplotlib import pyplot as plt

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 可视化训练集输入特征的第一个元素
plt.imshow(x_train[0], cmap=&apos;gray&apos;)  # 绘制灰度图
plt.show()

# 打印出训练集输入特征的第一个元素
print(&quot;x_train[0]:\n&quot;, x_train[0])
# 打印出训练集标签的第一个元素
print(&quot;y_train[0]:\n&quot;, y_train[0])

# 打印出整个训练集输入特征形状
print(&quot;x_train.shape:\n&quot;, x_train.shape)
# 打印出整个训练集标签的形状
print(&quot;y_train.shape:\n&quot;, y_train.shape)
# 打印出整个测试集输入特征的形状
print(&quot;x_test.shape:\n&quot;, x_test.shape)
# 打印出整个测试集标签的形状
print(&quot;y_test.shape:\n&quot;, y_test.shape)</code></pre><p>x未截完，可以看见，x是28<em>28的矩阵，每一个点，代表该处的灰度值<br>0表示黑色，255表示纯白色<br><img src="https://i.loli.net/2021/02/21/ws3MbZCXG4xVPi5.png" alt=""><br>y则是标签也就是该图片对应的数值是指多少。<br>可以看到，整个<code>x_train</code>是60000个28</em>28的矩阵，而<code>y_train</code>是60000个值，是一个列向量。<br><img src="https://i.loli.net/2021/02/21/HpIDnVXKeLSsh4B.png" alt="image.png"><br><img src="https://i.loli.net/2021/02/21/lT3OfDFC7H9tj5s.png" alt="image.png">   </p>
<h2 id="Sequential实现"><a href="#Sequential实现" class="headerlink" title="Sequential实现"></a>Sequential实现</h2><pre><code>import tensorflow as tf

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0  #归一化，使0-255的灰度值变成0-1之间的数值

model = tf.keras.models.Sequential([                #输入层是不用定义的
    tf.keras.layers.Flatten(),                      #把输入特征拉直为一维数组
    tf.keras.layers.Dense(128, activation=&apos;relu&apos;),      #隐藏层，激活函数relu
    tf.keras.layers.Dense(10, activation=&apos;softmax&apos;)    #输出层，用softmax使输出符合概率分布
])

#配置训练方法
model.compile(optimizer=&apos;adam&apos;,  #优化器
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),   #因为不是原始输出，而是用了概率分布，所以用false
            metrics=[&apos;sparse_categorical_accuracy&apos;]) #数据集标签是数值，神经网络输出是概率分布

model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1)
model.summary()</code></pre><h2 id="class实现"><a href="#class实现" class="headerlink" title="class实现"></a>class实现</h2><pre><code>import tensorflow as tf
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras import Model

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0


class MnistModel(Model):
    def __init__(self):
        super(MnistModel, self).__init__()
        self.flatten = Flatten()
        self.d1 = Dense(128, activation=&apos;relu&apos;)
        self.d2 = Dense(10, activation=&apos;softmax&apos;)

    def call(self, x):
        x = self.flatten(x)
        x = self.d1(x)
        y = self.d2(x)
        return y


model = MnistModel()

model.compile(optimizer=&apos;adam&apos;,
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
            metrics=[&apos;sparse_categorical_accuracy&apos;])

model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1)
model.summary()</code></pre>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/19/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/19/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%89/" class="post-title-link" itemprop="url">Tensorflow学习笔记(三)</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-02-19 09:45:00 / Modified: 14:01:50" itemprop="dateCreated datePublished" datetime="2021-02-19T09:45:00+08:00">2021-02-19</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>用Sequential可以搭建出上层输出就是下层输入的顺序网络结构，但无法写出一些带有跳连的非顺序网络结构。<br>此时选择用类class搭建神经网络结构<br><strong>🎱六步法</strong>   </p>
<ul>
<li>import</li>
<li>train，test</li>
<li>class MyModel(Model) model=MyModel   </li>
<li>model.compile</li>
<li>model.fit</li>
<li>model.summary</li>
</ul>
<h1 id="class类封装神经网络结构"><a href="#class类封装神经网络结构" class="headerlink" title="class类封装神经网络结构"></a>class类封装神经网络结构</h1><pre><code>✨
class MyModel(Model):
    def __init__(self):
        super(MyModel,self).__init__()
        定义网络结构块
    def call(self,x):
        调用网络结构块，实现前向传播
        return y
model = MyModel()
✨



🎆#鸢尾花   

import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras import Model
from sklearn import datasets
import numpy as np

x_train = datasets.load_iris().data
y_train = datasets.load_iris().target

np.random.seed(116)
np.random.shuffle(x_train)
np.random.seed(116)
np.random.shuffle(y_train)
tf.random.set_seed(116)

class IrisModel(Model):
    def __init__(self):
        super(IrisModel, self).__init__()
        self.d1 = Dense(3, activation=&apos;softmax&apos;, kernel_regularizer=tf.keras.regularizers.l2())

    def call(self, x):
        y = self.d1(x)
        return y

model = IrisModel()

model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1),
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
            metrics=[&apos;sparse_categorical_accuracy&apos;])

model.fit(x_train, y_train, batch_size=32, epochs=500, validation_split=0.2, validation_freq=20)
model.summary()</code></pre>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/18/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/18/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C/" class="post-title-link" itemprop="url">Tensorflow学习笔记(二)</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-02-18 19:23:12 / Modified: 20:48:59" itemprop="dateCreated datePublished" datetime="2021-02-18T19:23:12+08:00">2021-02-18</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="使用八股搭建神经网络"><a href="#使用八股搭建神经网络" class="headerlink" title="使用八股搭建神经网络"></a>使用八股搭建神经网络</h1><p><strong>用Tensorflow API：tf.keras搭建网络八股</strong>   </p>
<p><strong>🎱六步法</strong></p>
<ul>
<li>import相关模块   </li>
<li>确定训练集和测试集<br>  指定训练集的输入特征和标签；<br>  指定测试集的输入特征和标签。   </li>
<li>在<code>Sequential()</code>中搭建网络结构，逐层描述每层网络<br>  相当于走一遍前向传播   </li>
<li>在<code>compile()</code>中配置训练方法<br>  告知训练时选择哪种优化器；<br>  选择哪种损失函数；<br>  选择哪种评测指标；   </li>
<li>在<code>fit()</code>中执行训练过程<br>  告知训练集和测试集的输入特征和标签；<br>  每个batch是多少；<br>  迭代多少次训练集；  </li>
<li>用<code>summary()</code>打印出网络的结构和参数统计  </li>
</ul>
<h2 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential()"></a>Sequential()</h2><pre><code># 描述从输入层到输出层，每一层的网络结构
✨model = tf.keras.models.Sequential([网络结构])     

# 每一层的网络结构，可以是👇  

#拉直层  
#该层不含计算，只是形状转换
#把输入特征拉直变成一维数组
tf.keras.layers.Flatten()


#全连接层  
tf.keras.layers.Dense(神经元个数,activation=&apos;激活函数&apos;,kernel_regularizer=那种正则化)   
#activation(以字符串形式给出)可选: relu、softmax、sigmoid、tanh   
#kernel_regularizer 可选: tf.keras.regularizers.l1()、tf.keras.regularizers.l2()   

#卷积层  
tf.keras.layers.Conv2D(filters=卷积核个数,kernel_size=卷积核尺寸,strides=卷积步长,padding=&quot;valid&quot;or&quot;same&quot;)    


#LSTM层(循环神经网络层)  
tf.keras.layers.LSTM()</code></pre><h2 id="compile"><a href="#compile" class="headerlink" title="compile()"></a>compile()</h2><pre><code>✨model.complie(optimizer=优化器,loss=损失函数,metrics=[&quot;准确率&quot;])



#优化器optimizer可以是字符串形式给出的👇   
&gt;&gt;&apos;sgd&apos; or tf.keras.optimizers.SGD(lr=学习率,momentum=动量参数) 

&gt;&gt;&apos;adagrad&apos; pr tf.keras.optimizers.Adagrad(lr=*)

&gt;&gt;&apos;adadelta&apos; or tf.keras.optimizers.Adadelta(lr=*)   



#损失函数loss👇   
&gt;&gt;&apos;mse&apos; or tf.keras.losses.MeanSquaredError()  

&gt;&gt;&apos;sparse_categorical_crossentropy&apos; or tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)  
#👆这个函数的参数是在询问是否原始输出；
#神经网络预测结果输出前经过概率分布，就不是原始输出，此时就是False



#网络评测指标Metrics👇:  
&gt;&gt;&apos;accuracy&apos;:y_和y都是数值，如y_=[1],y=[1]  

&gt;&gt;&apos;categorical_accuracy&apos;:y_和y都是独热码(概率分布),如y_=[0,1,0],y=[0.256,0.695,0.048] 

&gt;&gt;&apos;sparse_categorical_accuracy&apos;:y_是数值，y是独热码(概率分布),如y_=[1],y=[0.256,0.695.0.048]   </code></pre><h2 id="fit"><a href="#fit" class="headerlink" title="fit()"></a>fit()</h2><pre><code>✨model.fit(训练集的输入特征,训练集的标签,batch_size= , epochs= ,validation_data=(测试集的输入特征,测试集的标签),validation_split=从训练集划分多少比例给测试集,validation_freq=多少次epoch测试一次)   </code></pre><ul>
<li>validation_data与validation_split两者选其一  </li>
</ul>
<h2 id="model-summay"><a href="#model-summay" class="headerlink" title="model.summay()"></a>model.summay()</h2><p>打印出网络的结构和参数统计<br><img src="https://i.loli.net/2021/02/18/1nCZIvTzxstSBQM.png" alt="image.png">   </p>
<h2 id="鸢尾花示例"><a href="#鸢尾花示例" class="headerlink" title="鸢尾花示例"></a>鸢尾花示例</h2><pre><code>import tensorflow as tf
from sklearn import datasets
import numpy as np

x_train = datasets.load_iris().data
y_train = datasets.load_iris().target

np.random.seed(116)
np.random.shuffle(x_train)
np.random.seed(116)
np.random.shuffle(y_train)
tf.random.set_seed(116)

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(3, activation=&apos;softmax&apos;, kernel_regularizer=tf.keras.regularizers.l2())
])

model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1),
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
            metrics=[&apos;sparse_categorical_accuracy&apos;])

model.fit(x_train, y_train, batch_size=32, epochs=500, validation_split=0.2, validation_freq=20)

model.summary()</code></pre>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/27/%E9%B8%A2%E9%B8%9F%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/27/%E9%B8%A2%E9%B8%9F%E9%9B%86/" class="post-title-link" itemprop="url">鸢鸟集</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-27 20:52:42" itemprop="dateCreated datePublished" datetime="2021-01-27T20:52:42+08:00">2021-01-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-30 21:26:29" itemprop="dateModified" datetime="2021-01-30T21:26:29+08:00">2021-01-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="🎏实现鸢尾花分类整体思路"><a href="#🎏实现鸢尾花分类整体思路" class="headerlink" title="🎏实现鸢尾花分类整体思路"></a>🎏实现鸢尾花分类整体思路</h1><h2 id="🎋准备数据"><a href="#🎋准备数据" class="headerlink" title="🎋准备数据"></a>🎋准备数据</h2><ul>
<li>数据集读入</li>
<li>数据集乱序</li>
<li>生成训练集和测试集</li>
<li>配成（输入特征、标签）对，每次读入batch    </li>
</ul>
<h2 id="🎋搭建网络"><a href="#🎋搭建网络" class="headerlink" title="🎋搭建网络"></a>🎋搭建网络</h2><ul>
<li>定义神经网络中所有可训练参数    </li>
</ul>
<h2 id="🎋参数优化"><a href="#🎋参数优化" class="headerlink" title="🎋参数优化"></a>🎋参数优化</h2><ul>
<li>嵌套循环迭代，with结构更新参数，显示当前loss   </li>
</ul>
<h2 id="🎋测试效果"><a href="#🎋测试效果" class="headerlink" title="🎋测试效果"></a>🎋测试效果</h2><ul>
<li>计算当前参数前后传播后的准确率，显示当前acc  </li>
</ul>
<h2 id="🎋acc-loss可视化"><a href="#🎋acc-loss可视化" class="headerlink" title="🎋acc/loss可视化"></a>🎋acc/loss可视化</h2><h1 id="🎏准备"><a href="#🎏准备" class="headerlink" title="🎏准备"></a>🎏准备</h1><h2 id="🎋数据集读入"><a href="#🎋数据集读入" class="headerlink" title="🎋数据集读入"></a>🎋数据集读入</h2><p>从<code>sklearn.datasets</code>中可以得到鸢鸟的数据包<br>也就是，首先要有<code>sklearn</code>包,通过<code>pip instal sklearn</code>获得</p>
<pre><code>from sklearn.datasets import load_iris
from pandas import DataFrame  #处理数据，形成表格，更直观
import pandas as pd

x_data = load_iris().data
y_data = load_iris().target
#获得特征和对应的标签

x_data = DataFrame(x_data, columns=[&apos;花萼长度&apos;, &apos;花萼宽度&apos;, &apos;花瓣长度&apos;, &apos;花瓣宽度&apos;]) # 为表格增加行索引（左侧）和列标签（上方）
pd.set_option(&apos;display.unicode.east_asian_width&apos;, True)  # 设置列名对齐

x_data[&apos;类别&apos;] = y_data  # 新加一列，列标签为‘类别’，数据为y_data

print(x_data)</code></pre><p><img src="https://i.loli.net/2021/01/27/u1WnPpVtriXq9Gj.png" alt="结果"></p>
<h2 id="🎱关于DataFrame"><a href="#🎱关于DataFrame" class="headerlink" title="🎱关于DataFrame"></a>🎱关于DataFrame</h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p>创建一个DataFrame，相当于这一堆数据就是一个表格，创建时，会默认给新增一列在最左侧，是索引，从0开始；<br>如果数据是字典型，则已经确定好了列名。<br>若是数组，则可通过<code>columns=[]</code>来命名各列。<br><img src="https://i.loli.net/2021/01/27/LOs6ztbnkuYgAPx.png" alt="例子"></p>
<h3 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h3><p>创建之后，就是一个可操作的DataFrame<br>则若要新增一列(最后一列)，可直接<code>x[&#39;列名&#39;]=[内容]</code>。<br>若要指定插入一列<code>x.insert(插入后所处的列数，列名，内容)</code><br><img src="https://i.loli.net/2021/01/27/AJx4Sdse9h2w1VU.png" alt="image.png"></p>
<h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p><strong>列</strong><br>可直接<code>x[列名]</code><br>当然可直接通过此赋值<code>x[列名]=[内容]</code><br><strong>行</strong><br>直接<code>x.loc[&#39;行名&#39;]</code>   </p>
<p><strong>行和列</strong>  </p>
<pre><code>x.iloc[:,:]   
#可以看到，第一个是几行，第二个是几列。
#注意，都是从0计数且前闭后开 </code></pre><p><img src="https://i.loli.net/2021/01/27/InPzHicRCvDZMyS.png" alt="image.png"></p>
<h3 id="索引补充"><a href="#索引补充" class="headerlink" title="索引补充"></a>索引补充</h3><p>索引除了最开始在创建时创建以外，在创建后也可以更改。   </p>
<ol>
<li><p>将自己的一列设置为索引<code>x.set_index([列名],drop=True)</code><br>drop默认是True，意思是，将该列作为索引后，不保存该列数据；改为False，则保存该列数据。<br><img src="https://i.loli.net/2021/01/27/jksDGTqL9dFHhWa.png" alt="image.png"></p>
</li>
<li><p>直接创建<code>x.index=[1,2,3,4,5]</code></p>
</li>
<li><p>还原成默认值<code>x.reset_index(drop=False)</code><br>drop默认值是False，是指将原来的索引值保留为数据；若为True，则原索引值删除。<br><img src="https://i.loli.net/2021/01/27/TbaqnWCr7gHPOLl.png" alt="image.png"></p>
</li>
</ol>
<h2 id="🎋数据集乱序"><a href="#🎋数据集乱序" class="headerlink" title="🎋数据集乱序"></a>🎋数据集乱序</h2><pre><code>np.random.seed(116) #是用相同的seed，使输入特征/标签一一对应
np.random.shuffle(x_data)
np.random.seed(116)
np.random.shuffle(y_data)
tf.random.set_seed(116)</code></pre><h2 id="🎋分为训练集和测试集"><a href="#🎋分为训练集和测试集" class="headerlink" title="🎋分为训练集和测试集"></a>🎋分为训练集和测试集</h2><pre><code>x_train = x_data[:-30]
y_train = y_data[:-30]
x_test = x_data[-30:]
y_test = y_data[-30:]</code></pre><h2 id="🎋配对"><a href="#🎋配对" class="headerlink" title="🎋配对"></a>🎋配对</h2><pre><code>train_db = tf.data.Dataset.from_tensor_slices((x_trainm4,y_train)).batch(32)
test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(32)</code></pre><h1 id="🎏搭建网络"><a href="#🎏搭建网络" class="headerlink" title="🎏搭建网络"></a>🎏搭建网络</h1><pre><code>w1 = tf.Variable(tf.random.truncated_normal([4,3],stddev=0.1,seed=1))
b1 = tf.Variable(tf.random.truncated_normal([4,3],stddev=0.1,seed=1))

for epoch in range(epoch):
    for step,(x_train,y_train) in enumerate(train_db):
        with tf.GradientTape() as tape:
            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算
            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）
            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy
            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)
            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确

            grads = tape.gradient(loss,[w1,b1])
            w.assign_sub(lr*grads[0])
            b1.assign_sub(lr*grads[1])
        print(&quot;Epoch{},loss:{}&quot;.format(epoch,loss_all/4))</code></pre><h1 id="🎏计算准确率"><a href="#🎏计算准确率" class="headerlink" title="🎏计算准确率"></a>🎏计算准确率</h1><pre><code>for x_test,y_test in test_db:
    y = tf.matul(h,w)+b  #预测结果
    y = tf.nn.softmax(y)  #y符合概率分布  
    pred = tf.argmax(y,axis=1) #返回y中最大值的索引，即预测的分类  
    pred = tf.cast(pred,dtype = y_test.dtype) #调整数据类型与标签一致  
    correct = tf.cast(tf.equal(pred,y_test),dtype = tf.int32)
    correct = tf.reduce_sum(correct) $将每个batch的correct数加起来
    total_correct +=int(correct)  #将所有batch中的correct数加起来  
    total_number += x_test.shape[0]
acc = total_correct/total_number
print(&quot;test_acc:&quot;,acc)

plt.title(&quot;Acc Curve&quot;)
plt.xlabel(&quot;Epoch&quot;)
plt.ylabel(&quot;Acc&quot;)
plt.plot(test_acc,label=&quot;$Accuracy$&quot;)  
plt.legend()
plt.show()</code></pre>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/24/Tensorflow-Anaconda-Pycharm%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/24/Tensorflow-Anaconda-Pycharm%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/" class="post-title-link" itemprop="url">Tensorflow+Anaconda+Pycharm环境安装</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-24 15:39:12" itemprop="dateCreated datePublished" datetime="2021-01-24T15:39:12+08:00">2021-01-24</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/01/Matlab%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/01/Matlab%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" class="post-title-link" itemprop="url">Matlab期末复习</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-01 22:32:32" itemprop="dateCreated datePublished" datetime="2020-12-01T22:32:32+08:00">2020-12-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-24 15:36:45" itemprop="dateModified" datetime="2021-01-24T15:36:45+08:00">2021-01-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="DAY-1"><a href="#DAY-1" class="headerlink" title="DAY 1"></a>DAY 1</h1><ul>
<li><p><strong>小括号()</strong><br>  只表示运算级别——在运算中优先计算；若有多个小括号则先算最里面的。<br><strong>中括号[]</strong><br>  只用于生成矩阵和向量<br><strong>花括号{}</strong><br>  生成单元数组；在生成结构体的一种方法<code>struct(&#39;变量名&#39;,{&#39;元素名&lt;--可多个&#39;},)</code>也就是如果用<code>struct()</code>里面的元素是多个时，就用花括号包含起来    </p>
</li>
<li><p><strong>数组/矩阵的行列</strong><br>  <strong>逗号</strong><code>,</code>是同一行不同列元素分开<br>  <strong>分号</strong><code>;</code>是不同行</p>
<pre><code>&gt;&gt;x=[1, 2 3;5 ,6,4]
1 2 3
5 6 4</code></pre></li>
</ul>
<h1 id="DAY-2"><a href="#DAY-2" class="headerlink" title="DAY 2"></a>DAY 2</h1><h2 id="基本运算函数"><a href="#基本运算函数" class="headerlink" title="基本运算函数"></a>基本运算函数</h2><ul>
<li><p>三角函数相关  </p>
<ul>
<li><strong>三角函数</strong>有两种形式<br>分别为计算<strong>弧度形式</strong><code>cos/sin/tan/csc/sec/cot</code>;<br>计算<strong>角度形式</strong>在后面加<strong>d</strong> <code>cosd/sind/tand/cscd/secd</code>  </li>
<li><strong>反三角函数</strong>同样有两种形式，如果要算<strong>角度</strong>就在后面加<strong>d</strong><br>基本形式为<code>acos/asin/atan/acsc/asec...</code><br>角度<code>acosd...</code></li>
<li><strong>双曲函数</strong>，双曲正/余…弦,实际上就是在三角函数(弧度制)的后面加<strong>h</strong>;若是<strong>反双曲函数</strong>则再在前面加<strong>a</strong>即可，比如双曲余弦<code>cosh</code>;反双曲余弦<code>acosh</code></li>
</ul>
</li>
<li><p>基本运算  </p>
<ul>
<li><p><strong>乘方</strong><code>^</code>  </p>
<pre><code>&gt;&gt;2^2
4</code></pre></li>
<li><p><strong>以e为底的幂</strong><code>exp()</code></p>
<pre><code>&gt;&gt;exp(1)
%等价于e的一次方   </code></pre></li>
<li><p><strong>求对数——以e为底</strong><code>log()</code><br>若为以其他数字为底求对数</p>
</li>
<li><p><strong>绝对值求解</strong><code>abs()</code></p>
</li>
<li><p><strong>判断是否为复数</strong><code>isreal()</code></p>
</li>
<li><p><strong>取整</strong><code>fix()</code></p>
</li>
<li><p><strong>判断质数</strong><code>isprime()</code><br>📌注意，只能判断非负整数！不能判断浮点数  </p>
</li>
</ul>
</li>
</ul>
<h1 id="DAY-4"><a href="#DAY-4" class="headerlink" title="DAY 4"></a>DAY 4</h1><h2 id="多项式"><a href="#多项式" class="headerlink" title="多项式"></a>多项式</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/20/mnist-%E8%AF%86%E5%88%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/20/mnist-%E8%AF%86%E5%88%AB/" class="post-title-link" itemprop="url">mnist手写识别</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-20 18:43:09" itemprop="dateCreated datePublished" datetime="2020-11-20T18:43:09+08:00">2020-11-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-15 20:32:55" itemprop="dateModified" datetime="2021-01-15T20:32:55+08:00">2021-01-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Prep"><a href="#Prep" class="headerlink" title="Prep"></a>Prep</h1><h2 id="Keras数据集———MNIST手写字符数据集"><a href="#Keras数据集———MNIST手写字符数据集" class="headerlink" title="Keras数据集———MNIST手写字符数据集"></a>Keras数据集———MNIST手写字符数据集</h2><pre><code>from keras.datasets import mnist
(x_train,y_train),(x_test,y_test) = mnist.load_data()</code></pre><p>返回的两个元组：  </p>
<ul>
<li><strong>x_train, x_test:</strong><br>uint8 数组表示的灰度图像，尺寸为 (num_samples, 28, 28)。</li>
<li><strong>y_train, y_test:</strong><br>uint8 数组表示的数字标签（范围在 0-9 之间的整数），尺寸为 (num_samples,)。</li>
</ul>
<p>查看一下我们的数据集  </p>
<pre><code>(x_train,y_train),(x_test,y_test)=mnist.load_data()
for i in range(9):
plt.subplot(3,3,i+1)
plt.imshow(x_train[i], cmap=&apos;gray&apos;, interpolation=&apos;none&apos;)
plt.title(&quot;Class {}&quot;.format(y_train[i]))

plt.show()</code></pre><p><img src="https://i.loli.net/2020/11/20/mSG7Fi9EABoN83z.png" alt="数据集部分显示"><br><strong>注意：<code>plt.imshow()</code>只是处理图像，并不会显示图像。需要加上<code>plt.show()</code></strong>  </p>
<p><strong>🎱补充:<code>len(矩阵)</code>返回的是矩阵的行数</strong></p>
<h2 id="标签准备"><a href="#标签准备" class="headerlink" title="标签准备"></a>标签准备</h2><h3 id="One-Hot-编码"><a href="#One-Hot-编码" class="headerlink" title="One-Hot 编码"></a>One-Hot 编码</h3><p>One-Hot编码，又称为一位有效编码，主要是采用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。</p>
<p>One-Hot编码是分类变量作为二进制向量的表示。这首先要求将分类值映射到整数值。然后，每个整数值被表示为二进制向量，除了整数的索引之外，它都是零值，它被标记为1。<br>实际上就是根据样本所具有的特征进行<code>0/1</code>赋值。<br>比如对<code>hello world</code>进行one hot编码。该句由字母和空格组成。字母的特征有26个特征，加上空格则一共有27个。<br><img src="https://i.loli.net/2020/11/20/Gb6jxhzICdT4sQv.png" alt="示例"><br>再比如若对 <strong>[“中国”,”美国”,”日本”,”美国”]</strong> 进行编码。  </p>
<ul>
<li>确定要编码的对象– <strong>[“中国”,”美国”,”日本”,”美国”]</strong>   </li>
<li>确定分类变量–<strong>中国  美国  日本</strong> 共三种类别<br>  即是有三个样本，每个样本有三个特征，并将其转化为二进制向量。  </li>
</ul>
<p>我们首先进行特征的整数编码： <strong>中国–0，美国–1，日本–2</strong> ，并将特征按照从小到大排列<br><img src="https://img2018.cnblogs.com/blog/901213/201907/901213-20190730115423074-1198386169.png" alt="示例">  </p>
<p>🎱<strong>Keras实现</strong>   </p>
<pre><code>from keras.utils import np_utils
&gt;&gt;y_train =np_utils.to_categorical(y_train,num_classes=10)  
#十类，应该是用十个特征进行表示，前提是y_train中的数字最大不能超过10。这实际上很像是对点标签，如果是5，就在5处打勾(变为1，其余为0)。所以要保证num_classes要大于max(y)  </code></pre><h1 id="搭建网络"><a href="#搭建网络" class="headerlink" title="搭建网络"></a>搭建网络</h1><p><strong>创建Sequential模型</strong>   </p>
<ul>
<li><p>将层的列表传递给Sequential的构造函数。   </p>
<pre><code>model = Sequential([
 Dense(units = 10,input_dim = 784,bias_initializer = &apos;one&apos;,activation=&apos;softmax&apos;)]) </code></pre></li>
<li><p>使用<code>model.add()</code>的方法将各层添加到模型中  </p>
</li>
</ul>
<pre><code>model = Sequential()
model.add(Dense(10, input_dim=784))
model.add(Activation(&apos;softmax&apos;))  </code></pre><p><strong>Dense</strong><br><img src="https://i.loli.net/2020/11/20/FaNRyqT3n1CApVs.png" alt=""></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/28/python%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/28/python%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E7%B1%BB/" class="post-title-link" itemprop="url">python学习——类</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-28 22:39:14" itemprop="dateCreated datePublished" datetime="2020-10-28T22:39:14+08:00">2020-10-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-10-30 22:56:10" itemprop="dateModified" datetime="2020-10-30T22:56:10+08:00">2020-10-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="定义类"><a href="#定义类" class="headerlink" title="定义类"></a>定义类</h1><pre><code>class Student(object):
    pass</code></pre><p>class后面紧跟着的就是类名，即<code>Student</code> ，后面紧接着的<code>(object)</code>表示该类是从哪个类继承下来的。<br>    如果没有合适的继承类，就用<code>object</code>类，这是所有类都会继承的类。  </p>
<h1 id="创建实例"><a href="#创建实例" class="headerlink" title="创建实例"></a>创建实例</h1><p>创建实例直接<code>example = Student(parameter)</code><br>如果在类的定义中没有绑定属性。也就是在我们定义类的时候，我们规定，所有实例都必须具有一些属性，就可以在定义类时绑定属性。<br>如果不绑定属性也是可以的。那么就不传入参数<code>example = Student()</code><br>此时，可以自由定义属性 <strong><em>(绑定了属性也是可以自由定义，只是在于，如果了绑定了，就相当于规定了在我定义这个实例时，就必须要具有这些属性)</em></strong>   </p>
<pre><code>&gt;&gt;&gt; amy = Student()
&gt;&gt;&gt; amy.name=&quot;Amy Smith&quot;
&gt;&gt;&gt; amy.name
&apos;Amy Smith&apos;</code></pre><p>如果在类中绑定了属性   </p>
<pre><code>class Student():
    def __init__(self,name,score):
        self.name=name
        self.score=score</code></pre><p><strong>注释：</strong> 在类中绑定属性，就是通过定义一个特殊的方法<code>__init__</code>，其第一个参数  <strong><em>(包括后面所有在类中定义的方法)</em></strong> 都是<code>self</code>。因为<code>self</code>就指向创建的实例本身。其后的参数就是我们绑定的属性。   </p>
<p>此后在创建实例时，就要传入相应的参数。   </p>
<pre><code>&gt;&gt;&gt; amy = Student(&quot;Amy Smith&quot;,95)
&gt;&gt;&gt; amy.name
&quot;Amy Smith&quot;  </code></pre><p>当然属性也不是一层不变的。<br>我们可以更改属性值。  </p>
<pre><code>&gt;&gt;&gt;amy.name=&quot;Tony&quot;  
&gt;&gt;&gt;amy.name
&quot;Tony&quot;</code></pre><p>也就是说外部代码可以自由地修改实例的属性。  </p>
<p>📌如果要让内部属性不被外部访问，可以把属性的名称前加两个下划线<code>__</code>，此时如果实例的变量名以<code>___</code>开头，就变成一个私有变量，只有内部可以访问，外部不能访问<br><img src="https://i.loli.net/2020/10/30/aeglV2YkQhDmu9B.png" alt="示例">   </p>
<p><strong>注：</strong> 实际上并不是外部不能访问了，而是Python解释器将<code>__name</code>变成了<code>_Student__name</code>  </p>
<p><img src="https://i.loli.net/2020/10/30/ZU9kohD1uGCKSQz.png" alt="示例"><br>可以看到通过我们定义的方法可以进行访问、修改属性。也可以看到我们仍然是可以访问私有变量的，只是其名字变了。<br>同时我们也可以看到，在其中的<code>jack.__name=&#39;mike&#39;</code> 实际上并没有实现访问<code>__name</code>变量，而是自己又创了一个属性，这个属性的名字是<code>__name</code>，其值是<code>&#39;mike&#39;</code>   </p>
<p><strong>补充：</strong> 在Python中，变量名类似<code>__xx__</code>的，是特殊变量，是可以直接访问的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.1.1
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
